{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf2_env","language":"python","name":"tf2_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"AutoEncoder_Multitask_Step1.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"QE0wnDWr1C-W"},"source":["# AutoEncoder for multitask \n","\n","1. Imports the unlabeled data\n","2. Train the autoencoder model\n","3. Save the encoder weights for further use in the multitask model\n","\n","\n","## Requirements : \n","| Library | version | version name |\n","| :---        |    :----:   |   ------:  |\n","| cudatoolkit |   9.0 | h13b8566_0 |\n","| cudnn |                     7.6.5 |                cuda9.0_0 |  \n","|ipykernel|                 5.3.4|            py37h5ca1d4c_0|    \n","|ipython |                  7.18.1|           py37h5ca1d4c_0|    \n","|jupyter_client|            6.1.7|                      py_0|    \n","|jupyter_core|              4.6.3|                    py37_0|    \n","|keras-applications|        1.0.8|                      py_1|  \n","|keras-preprocessing|       1.1.0|                      py_1 | \n","|matplotlib|                3.3.3|                    pypi_0|    \n","|matplotlib-base|           3.3.2|            py37h817c723_0|  \n","|nibabel|                   3.2.1|                    pypi_0|    \n","|numpy|                     1.19.2|           py37h54aff64_0|\n","|opencv|                    3.4.2|            py37h6fd60c2_1|  \n","|pandas|                    1.1.3|            py37he6710b0_0|  \n","|pillow|                    8.0.1|            py37he98fc37_0|  \n","|py-xgboost|                0.90|             py37he6710b0_1|    \n","|python|                    3.7.9|                h7579374_0|  \n","|scikit-image     |         0.17.2|                   pypi_0|    \n","|scikit-learn     |         0.23.2|           py37h0573a6f_0|    \n","|scipy            |         1.5.2  |          py37h0b6359f_0|  \n","|seaborn          |         0.11.0 |                    py_0|  \n","|tensorboard     |          1.14.0 |          py37hf484d3e_0|  \n","|tensorflow     |           1.14.0 |         gpu_py37hae64822_0|  \n","|tensorflow-gpu|            1.14.0 |              h0d30ee6_0|  "]},{"cell_type":"code","metadata":{"id":"Q0kBbNn40xD9"},"source":["# Importing important files\n","import pandas as pd\n","import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","from tensorflow.keras import backend as K\n","import nibabel as nib\n","import cv2\n","import time\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from tensorflow.keras.utils import to_categorical\n","\n","from prep_data import get_roi, get_all_subjects, get_subject, get_subject_list, pad_to_shape, remove_padding\n","from PatchGenerator import PatchGenerator\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rcqjg-00xEG"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","# import models\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications import ResNet50,DenseNet169,InceptionResNetV2,VGG16\n","from tensorflow.keras.layers import Conv2DTranspose\n","\n","from tensorflow.keras.layers import Flatten,concatenate,Input,Activation, GlobalAveragePooling2D,GlobalMaxPooling2D, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Lambda, AveragePooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvjyO4ll0xEI"},"source":["# importing the unlabeled data\n","x_train_1 = np.load('../Data/Nimhans_new_complete_3mod_X.npy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XX8SHfwS0xEJ"},"source":["print(x_train_1.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"skSp8RW50xEK"},"source":["x_train_a = np.append(x_train, x_train_1, axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOEUpVQ40xEK"},"source":["x_train_a.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dgmNwojF0xEL"},"source":["plt.imshow(x_train_a[1,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBLk8_QH0xEP"},"source":["def autoEncoder(ip):\n","    \"\"\"\n","      Defines the encoder and decoder of the autoencoder\n","    \"\"\"\n","    # Encodeer\n","    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same', input_shape = (128, 128, 1), name=\"EncoderLayer_0_Conv2D_0\")(ip)\n","    conv0 = Conv2D(64, (3, 3), activation='relu', padding='same', name=\"EncoderLayer_0_Conv2D_1\")(conv0)\n","    pool0 = MaxPooling2D((2, 2), padding='same', name=\"EncoderLayer_0_Pool\")(conv0)\n","    norm0 = BatchNormalization(name=\"EncoderLayer_0_BatchNorm\")(pool0)\n","    \n","    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same', name=\"EncoderLayer_1_Conv2D_0\")(norm0)\n","    conv1 = Conv2D(128, (3, 3), activation='relu', padding='same', name=\"EncoderLayer_1_Conv2D_1\")(conv1)\n","    pool1 = MaxPooling2D((2, 2), padding='same', name=\"EncoderLayer_1_Pool\")(conv1)\n","    norm1 = BatchNormalization(name=\"EncoderLayer_1_BatchNorm\")(pool1)\n","    \n","    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same', name=\"EncoderLayer_2_Conv2D_0\")(norm1)\n","    conv2 = Conv2D(256, (3, 3), activation='relu', padding='same', name=\"EncoderLayer_2_Conv2D_1\")(conv2)\n","    pool2 = MaxPooling2D((2, 2), padding='same', name=\"EncoderLayer_2_Pool\")(conv2)\n","    norm2 = BatchNormalization(name=\"EncoderLayer_2_BatchNorm\")(pool2)\n","    \n","    conv3 = Conv2D(512, (3, 3), activation='relu', padding='same', name=\"BottleNeckLayer_3_Conv2D_0\")(norm2)\n","    norm3 = BatchNormalization(name=\"EncoderLayer_3_BatchNorm\")(conv3)\n","    drop3 = Dropout(0.5, name=\"BottleNeckLayer_3_Dropout\")(conv3)\n","    \n","    # Latent Space\n","    encoded = MaxPooling2D((2, 2), padding='same',name= \"BottleNeckLayer_0_Pool\")(conv3)\n","\n","    # at this point the representation is (8,8,512) i.e. 128-dimensional\n","    # Decoder\n","    deconv0 = Conv2DTranspose(512, (3, 3), activation='relu', padding='same', strides = 2, name=\"DecoderLayer_0_DeConv_0\")(encoded)\n","    merge0 = concatenate([drop3,deconv0], name=\"DecoderLayer_0_concatenate\")\n","    deconv0 = Conv2DTranspose(512, (3, 3), activation='relu', padding='same', name=\"DecoderLayer_0_DeConv_1\")(merge0)\n","    denorm0 = BatchNormalization(name=\"DecoderLayer_0_BatchNorm\")(deconv0)\n","    \n","    deconv1 = Conv2DTranspose(256, (3, 3), activation='relu', padding='same', name=\"DecoderLayer_1_DeConv_0\")(denorm0)\n","    merge1 = concatenate([norm2,deconv1], name=\"DecoderLayer_1_concatenate\")\n","    deconv1 = Conv2DTranspose(256, (3, 3), activation='relu', padding='same', strides = 2, name=\"DecoderLayer_1_DeConv_1\")(merge1)\n","    denorm1 = BatchNormalization(name=\"DecoderLayer_1_BatchNorm\")(deconv1)\n","    \n","    deconv2 = Conv2DTranspose(128, (3, 3), activation='relu', padding='same', name=\"DecoderLayer_2_DeConv_0\")(denorm1)\n","    merge2 = concatenate([norm1,deconv2], name=\"DecoderLayer_2_concatenate\")\n","    deconv2 = Conv2DTranspose(128, (3, 3), activation='relu', padding='same', strides = 2, name=\"DecoderLayer_2_DeConv_1\")(merge2)\n","    denorm2 = BatchNormalization(name=\"DecoderLayer_2_BatchNorm\")(deconv2)\n","    \n","    deconv3 = Conv2DTranspose(64, (3, 3), activation='relu', padding = 'same', name=\"DecoderLayer_3_DeConv_0\")(denorm2)\n","    merge3 = concatenate([norm0,deconv3], name=\"DecoderLayer_3_concatenate\")\n","    deconv3 = Conv2DTranspose(64, (3, 3), activation='relu', padding = 'same', strides = 2, name=\"DecoderLayer_3_DeConv_1\")(merge3)\n","    denorm3 = BatchNormalization(name=\"DecoderLayer_3_BatchNorm\")(deconv3)\n","    \n","    decoded = Conv2D(1,(3, 3), activation='sigmoid', padding='same', name=\"FinalConv\")(denorm3)\n","\n","    return decoded"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FF6Y-NEE0xEQ"},"source":["ip1 = Input(shape=(128,128,1))\n","AutoEncoder1 = Model(inputs=ip1,outputs=autoEncoder(ip1))\n","AutoEncoder1.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObRl2Wul0xER"},"source":["from tensorflow.keras.utils import plot_model\n","plot_model(AutoEncoder1, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rRmRAhtu0xES"},"source":["# Defining the dice loss coefficient\n","def dice_coef(y_true, y_pred, smooth=1):\n","    \"\"\"\n","    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n","         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n","    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n","    \n","    \"\"\"\n","    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n","    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n","\n","def dice_coef_loss(y_true, y_pred):\n","    return 1-dice_coef(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFjthETV0xES"},"source":["AutoEncoder1.compile(optimizer='adam', loss=dice_coef_loss, metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1euNEP30xET"},"source":["train_steps = len(train_datagen)\n","test_steps = len(test_datagen)\n","print(train_steps, test_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-UDfcjq0xET"},"source":["filename=os.path.join('logs','AutoEncoder_2_complete.csv')\n","filepath=os.path.join('weights','AutoEncoder_2_complete.hdf5')\n","csv_log = CSVLogger(filename, separator=',', append=True)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n","rl = ReduceLROnPlateau(monitor='acc',patience=5,min_delta=0.001,cooldown=5,factor=0.1)\n","tb = TensorBoard('./logs',histogram_freq=0)\n","callbacks_list = [csv_log,\n","                  checkpoint,\n","                  #rl,\n","                  tb\n","                 ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KjFiGu5S0xET"},"source":["filepath1 = os.path.join('weights','AutoEncoder_2_all.hdf5')\n","if os.path.exists(filepath1):\n","    AutoEncoder1.load_weights(filepath1, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zJhmYA-f0xEU"},"source":["X_train = x_train_a.astype('float32') / 255.\n","X_test = x_test.astype('float32') / 255."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHQFiYf70xEU"},"source":["plt.imshow(X_train[3,:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClPr7eMz0xEU"},"source":["epochs = 1000\n","AutoEncoder1.fit(X_train, X_train,\n","                epochs = epochs,\n","                batch_size = 64,\n","                shuffle=True,\n","                validation_data=(X_test, X_test),\n","                callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pr6gJRqJ0xEV"},"source":["decoded_imgs = AutoEncoder1.predict(X_test)\n","\n","n = 10\n","plt.figure(figsize=(20, 4))\n","for i in range(1, n + 1):\n","    # Display original\n","    ax = plt.subplot(2, n, i)\n","    plt.imshow(X_test[i+120,:])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # Display reconstruction\n","    ax = plt.subplot(2, n, i + n)\n","    plt.imshow(decoded_imgs[i+120])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oWdutA8w0xEV"},"source":["AutoEncoder1.save('../Model/TCGA_AutoEncoder_complete_1.h5')\n","\n","AutoEncoder1.save_weights('weights/TCGA_AutoEncoder_complete_1.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNlb0B6y0xEV"},"source":["x_train_a_ = x_train_1.astype('float32') / 255."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vePpvkdu0xEW"},"source":["decoded_imgs_mid = AutoEncoder1.predict(x_train_a_)\n","\n","n = 10\n","plt.figure(figsize=(20, 4))\n","for i in range(1, n + 1):\n","    # Display original\n","    ax = plt.subplot(2, n, i)\n","    plt.imshow(x_train_a_[i+25,:])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","\n","    # Display reconstruction\n","    ax = plt.subplot(2, n, i + n)\n","    plt.imshow(decoded_imgs_mid[i+25])\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visible(False)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jm0lYLhu0xEW"},"source":[""],"execution_count":null,"outputs":[]}]}