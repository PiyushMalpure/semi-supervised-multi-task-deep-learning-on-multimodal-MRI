{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf2_env","language":"python","name":"tf2_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"Semisupervised_Multitask_training.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"qXXaFik9ZgpT"},"source":["# Multitask-Training \n","This file is for training the semisupervised multitask model.\n","The steps performed in the model are :\n","1. Import the saved model from previous steps\n","2. Load weights (optional normaly the .h5 file contains the weights of the models)\n","3. Import the spyros preprocessed numpy images for training and testing with labels\n","4. Train the multitask network\n","\n","PS. This file also contains a sample code for zhou heatmaps. ( For HR-CAMs refer the HR-CAMs_Multitask.ipynb notebook)\n"]},{"cell_type":"code","metadata":{"id":"rVxvKAZ4YgmM"},"source":["# Importing the required libraries\n","\n","import pandas as pd\n","import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","from tensorflow.keras import backend as K\n","import nibabel as nib\n","import cv2\n","import time\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from tensorflow.keras.utils import to_categorical\n","\n","from prep_data import get_roi, get_all_subjects, get_subject, get_subject_list, pad_to_shape, remove_padding\n","from PatchGenerator import PatchGenerator\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G4El83atYgmU"},"source":["from tensorflow.keras import Model\n","from tensorflow.keras.applications import ResNet50,DenseNet169,InceptionResNetV2,VGG16\n","from tensorflow.keras.layers import Conv2DTranspose\n","\n","from tensorflow.keras.layers import Add, MaxPool2D, Flatten,concatenate,Input,Activation, GlobalAveragePooling2D,GlobalMaxPooling2D, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Lambda, AveragePooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDMssaiRYgmV"},"source":["# For importing single modalitiy images\n","\n","\"\"\"x_train = np.load('../Data/X_train_ML_3.npy')\n","y_train = np.load('../Data/Y_train_ML_3.npy')\n","x_test = np.load('../Data/X_test_ML_3.npy')\n","y_test = np.load('../Data/Y_test_ML_3.npy')\n","\n","\n","print(x_train.shape,y_train.shape)\n","print(x_test.shape,y_test.shape)\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2v-cOnTYgmW"},"source":["\"\"\"bkp_X_train = np.copy(x_train)\n","bkp_Y_train = np.copy(y_train)\n","bkp_X_test = np.copy(x_test)\n","bkp_Y_test = np.copy(y_test)\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M02B8qTEYgmX"},"source":["\"\"\"\n","# Coverting single mod to 3 channel by stacking \n","# To be used only while importing single mod images\n","def grayscale_to_3channel(x):\n","    x = np.squeeze(x)\n","    return np.stack([x,x,x],axis=-1)\n","\n","X_train = grayscale_to_3channel(bkp_X_train)\n","X_test = grayscale_to_3channel(bkp_X_test)\n","\n","input_shape = X_train.shape[1:]\n","print(input_shape)\n","\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aRdTPj7YgmX"},"source":["\"\"\"del(bkp_X_test)\n","del(bkp_X_train)\n","del(bkp_Y_test)\n","del(bkp_Y_train)\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l8PE8d1tYgmW"},"source":["# Importing the stacked 3 modality images \n","\n","x_train_stack = np.load('../Data/X_train_ML_3mod.npy')\n","y_train_stack = np.load('../Data/Y_train_ML_3mod.npy')\n","x_test_stack = np.load('../Data/X_test_ML_3mod.npy')\n","y_test_stack = np.load('../Data/Y_test_ML_3mod.npy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l2Pxd9O-YgmW"},"source":["plt.imshow(x_test_stack[6,:], cmap='gray')\n","plt.grid(None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdFbUfBDYgmX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"APhhdA0HYgmY"},"source":["# Data gen during runtime\n","datagen = ImageDataGenerator(\n","    width_shift_range = [0.2, 0.3],\n","    height_shift_range = [0.2, 0.3],    \n","    vertical_flip = True,\n","    horizontal_flip = True,\n","    rotation_range=15,\n","    zoom_range=[0.5,1.0],\n","    #channel_shift_range=0.2\n","#     fill_mode = 'constant',\n","#     cval=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K0olv6gaYgmY"},"source":["# This function is required as we are using multitask images to unwrap the Y labels array and map it with each output\n","# This function is called during the training of the multitask model\n","def generator_wrapper(generator):\n","    for batch_x,batch_y in generator:\n","        yield (batch_x,[batch_y[:,i] for i in range(4)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1fWAhmkXYgmY"},"source":["# Setting batches and creating train and test data gen\n","\n","batch_size = 8\n","\n","train_datagen = datagen.flow(X_train,y_train,\n","                             batch_size=batch_size,\n","                             shuffle=True,                             \n","                            )\n","\n","\n","test_datagen = ImageDataGenerator().flow(X_test,y_test,batch_size=batch_size,\n","                                         shuffle=True)\n","\n","#test_datagen = datagen.flow(X_test,y_test,batch_size=batch_size,\n","#                                         shuffle=True)\n","\n","print(len(train_datagen),len(test_datagen))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BEMQlvBkYgmY"},"source":["batch = test_datagen.next()\n","subject = np.random.randint(0,len(batch[1]))\n","print(subject,batch[1][subject])\n","\n","plt.figure()\n","#plt.subplot(1,2,1)\n","plt.imshow(batch[0][subject,:,:,0],cmap='gray')\n","\n","print(np.mean(batch[0]),np.std(batch[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"24qhgJwiYgmZ"},"source":["test_datagen.reset()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OJHZKtZqYgmZ"},"source":["# importing the model consisting of the trained autoencoder's encoder and multitask model\n","new_model = keras.models.load_model('../Model/TCGA_miccai_1.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8M0PNhYYgmZ"},"source":["# Loading weights just to be sure\n","filepath_init = 'weights/TCGA_miccai_1.hdf5'\n","new_model.load_weights(filepath_init)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I0WeypPjYgmZ"},"source":["new_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZswNTJL5Ygma"},"source":["# modifing trainability of the layers\n","for layer in new_model.layers:\n","    layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xiBSV7gSYgma"},"source":["# plotting model graph\n","from tensorflow.keras.utils import plot_model\n","plot_model(new_model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0HUx1KYwVLt"},"source":["# Creating custom loss function to mask the unavailable labels\n","mask_value = -1\n","def masked_loss_function(y_true, y_pred):\n","    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n","    return K.binary_crossentropy(y_true * mask, y_pred * mask)\n","\n","#model.compile(loss=masked_loss_function, optimizer='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSK69HhxYgmb"},"source":["# setting optimiser and loss_functions\n","adam = keras.optimizers.Adam(learning_rate=0.00003)\n","\n","new_model.compile(adam,[masked_loss_function, masked_loss_function, masked_loss_function, masked_loss_function],metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6VCrY23Ygmb"},"source":["train_steps = len(train_datagen)\n","test_steps = len(test_datagen)\n","print(train_steps, test_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lX4NUNI2Ygmb"},"source":["filename=os.path.join('logs','TCGA_MT_Miccai_3.csv')\n","filepath=os.path.join('weights','TCGA_MT_Miccai_3.hdf5')\n","csv_log = CSVLogger(filename, separator=',', append=True)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_output1_acc', verbose=1, save_best_only=True)\n","rl = ReduceLROnPlateau(monitor='val_output1_acc',patience=5,min_delta=0.001,cooldown=5,factor=0.1)\n","tb = TensorBoard('./logs',histogram_freq=0)\n","callbacks_list = [csv_log,\n","                  checkpoint,\n","                  rl,\n","                  tb\n","                 ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dmvL0ICoYgmc"},"source":["#filepath1 = os.path.join('weights','TCGA_MT_Miccai_1.hdf5')\n","if os.path.exists(filepath):\n","    new_model.load_weights(filepath, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"mBKINDVwYgmc"},"source":["epochs = 100\n","nm_H = new_model.fit(generator_wrapper(train_datagen), steps_per_epoch=train_steps, epochs=epochs,\n","                    verbose = 1,validation_data=generator_wrapper(test_datagen),validation_steps=test_steps,\n","                    callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WkAlKRcYgmc"},"source":["# create a new figure for the accuracies\n","accuracyNames = [\"output1_acc\", \"output2_acc\", \"output3_acc\", 'output4_acc']\n","plt.style.use(\"ggplot\")\n","(fig, ax) = plt.subplots(4, 1, figsize=(8, 8))\n","# loop over the accuracy names\n","for (i, l) in enumerate(accuracyNames):\n","    # plot the loss for both the training and validation data\n","    ax[i].set_title(\"Accuracy for {}\".format(l))\n","    ax[i].set_xlabel(\"Epoch #\")\n","    ax[i].set_ylabel(\"Accuracy\")\n","    ax[i].plot(np.arange(0, epochs), nm_H.history[l], label=l)\n","    ax[i].plot(np.arange(0, epochs), nm_H.history[\"val_\" + l],\n","        label=\"val_\" + l)\n","    ax[i].legend()\n","# save the accuracies figure\n","plt.tight_layout()\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qogaG_4lYgmc"},"source":["lossNames = [\"output1_loss\", \"output2_loss\", \"output3_loss\", 'output4_loss']\n","plt.style.use(\"ggplot\")\n","(fig, ax) = plt.subplots(4, 1, figsize=(8, 8))\n","# loop over the loss names\n","for (i, l) in enumerate(lossNames):\n","    # plot the loss for both the training and validation data\n","    ax[i].set_title(\"loss for {}\".format(l))\n","    ax[i].set_xlabel(\"Epoch #\")\n","    ax[i].set_ylabel(\"loss\")\n","    ax[i].plot(np.arange(0, epochs), nm_H.history[l], label=l)\n","    ax[i].plot(np.arange(0, epochs), nm_H.history[\"val_\" + l],\n","        label=\"val_\" + l)\n","    ax[i].legend()\n","# save the accuracies figure\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPN0Dd0gYgmd"},"source":["_test_data, _test_labels = test_datagen.__getitem__(np.random.randint(0,len(test_datagen)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0diztXJuYgmd"},"source":["## evaluate the model and predict on testing data\n","print('Evaluate')\n","a=new_model.evaluate(generator_wrapper(test_datagen),batch_size=batch_size,verbose=1,steps = 1)\n","print('val_loss , val_acc: ', a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8I5jBH-Ygmd"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.metrics import (accuracy_score, classification_report,\n","                              confusion_matrix, roc_auc_score, roc_curve)\n","\n","def get_roc(y_true, y_pred, positive_class_index=0):\n","    y_pred = np.copy(y_pred)[:, positive_class_index]\n","    return {'auroc': roc_auc_score(y_true, y_pred), 'roc': roc_curve(y_true, y_pred)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2vLes7nnYgmd"},"source":["y_pred_proba = new_model.predict_generator(test_datagen,verbose=1) \n","y_true = y_test\n","y_pred = y_pred_proba"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3yUMSMD_Ygme"},"source":["y_pred = np.array(y_pred).reshape(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4uO9uI-Ygme"},"source":["y_train.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9eKrSSpYgme"},"source":["y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvqpSeE_Ygme"},"source":["y_true = y_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mf3u_3IbYgme"},"source":["y_pred = np.array(y_pred).reshape(171,4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvmVW-I3Ygme"},"source":["# Classification report for Grade\n","rint(classification_report(y_true[:,0],y_pred[:,0].round()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TF-QwoaiYgmf"},"source":["# Classification report for IDH\n","print(classification_report(y_true[:,1],y_pred[:,1].round()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CuMqpdN1Ygmf"},"source":["# Classification report for MGMT\n","print(classification_report(y_true[:,2],y_pred[:,2].round()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVQy5_TpYgmf"},"source":["# Classification report for 1p19q\n","print(classification_report(y_true[:,3],y_pred[:,3].round()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2hBt4YRYgmf"},"source":["from sklearn.metrics import roc_curve, auc\n","from sklearn.multiclass import OneVsRestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PLIptrcCYgmg"},"source":["n_classes = 4 # number of classes for which roc needs to be plotted\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_true[:,i],y_pred[:,i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot of a ROC curve for a specific class\n","for i in range(n_classes):\n","    plt.figure()\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n","    #plt.plot([0, 1], [0, 1], 'k--')\n","    #plt.xlim([0.0, 1.0])\n","    #plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic example')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaAHylHEYgmg"},"source":["new_model.save('../Model/TCGA_miccai_trained_2.h5')\n","\n","new_model.save_weights('weights/TCGA_miccai_trained_2.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2m1cXeWYgmg"},"source":["print(len(y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vRmJtzXlYgmg"},"source":["print(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYAMWF2XYgmm"},"source":["#IDH\n","activation_layer = new_model.get_layer('fireop2_0/relu_expand3x3')\n","model_n = Model(inputs=new_model.inputs, outputs=activation_layer.output)\n","    \n","    \n","final_dense = new_model.get_layer('output2')\n","W = final_dense.get_weights()[0]\n","    \n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZVmBKoO7Ygmm"},"source":["img = np.copy(X_test)[[subject_id],:] #4dim img for pred\n","label_print = np.copy(y_test)[[subject_id],:]\n","fmaps = model_n.predict(img)[0]\n","\n","probs = new_model.predict(img)\n","pred = np.argmax(probs[0])\n","\n","#get the weights for the relevant class\n","w = W[:,pred]\n","print(w.shape)\n","\n","cam = fmaps.dot(w)\n","print(cam.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uC3TzcHyYgmm"},"source":["#upsample to img original size then plot\n","cam = sp.ndimage.zoom(cam, (16,16), order=1)\n","cam.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UGZGUA0CYgmm"},"source":["print(label_print)\n","plt.figure(figsize=(10,10))\n","plt.subplot(1,2,1)\n","#plt.imshow(img[0][:,:,0], alpha=0.9, cmap='gray')\n","plt.imshow(cam, cmap ='jet' , alpha=0.65)\n","plt.grid(b=None)\n","plt.subplot(1,2,2)\n","plt.imshow(img[0][:,:,1],cmap='gray')\n","plt.grid(b=None)\n","plt.show()"],"execution_count":null,"outputs":[]}]}