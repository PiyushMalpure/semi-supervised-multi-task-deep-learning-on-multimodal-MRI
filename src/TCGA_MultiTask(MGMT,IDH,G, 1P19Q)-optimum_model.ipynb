{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf2_env","language":"python","name":"tf2_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"TCGA_MultiTask(MGMT,IDH,G, 1P19Q)-optimum_model.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"D79p5VB2o3SQ"},"source":["# Multitask Model\n","This code is complete end to end building of a multitask model. Different steps in the code are : \n","1. Image preprocessing \n","2. Model design\n","3. Model Train\n","4. Post training analysis\n","\n","## Requirements \n","| Library | version | version name |\n","| :---        |    :----:   |   ------:  |\n","| cudatoolkit |   9.0 | h13b8566_0 |\n","| cudnn |                     7.6.5 |                cuda9.0_0 |  \n","|ipykernel|                 5.3.4|            py37h5ca1d4c_0|    \n","|ipython |                  7.18.1|           py37h5ca1d4c_0|    \n","|jupyter_client|            6.1.7|                      py_0|    \n","|jupyter_core|              4.6.3|                    py37_0|    \n","|keras-applications|        1.0.8|                      py_1|  \n","|keras-preprocessing|       1.1.0|                      py_1 | \n","|matplotlib|                3.3.3|                    pypi_0|    \n","|matplotlib-base|           3.3.2|            py37h817c723_0|  \n","|nibabel|                   3.2.1|                    pypi_0|    \n","|numpy|                     1.19.2|           py37h54aff64_0|\n","|opencv|                    3.4.2|            py37h6fd60c2_1|  \n","|pandas|                    1.1.3|            py37he6710b0_0|  \n","|pillow|                    8.0.1|            py37he98fc37_0|  \n","|py-xgboost|                0.90|             py37he6710b0_1|    \n","|python|                    3.7.9|                h7579374_0|  \n","|scikit-image     |         0.17.2|                   pypi_0|    \n","|scikit-learn     |         0.23.2|           py37h0573a6f_0|    \n","|scipy            |         1.5.2  |          py37h0b6359f_0|  \n","|seaborn          |         0.11.0 |                    py_0|  \n","|tensorboard     |          1.14.0 |          py37hf484d3e_0|  \n","|tensorflow     |           1.14.0 |         gpu_py37hae64822_0|  \n","|tensorflow-gpu|            1.14.0 |              h0d30ee6_0|  "]},{"cell_type":"code","metadata":{"id":"R29-7TYtoOg5"},"source":["# Importing the required libraries \n","\n","import pandas as pd\n","import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","from tensorflow.keras import backend as K\n","import nibabel as nib\n","import cv2\n","import time\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5mfUpTaBoOhB"},"source":["from prep_data import get_roi, get_all_subjects, get_subject, get_subject_list, pad_to_shape, remove_padding\n","from PatchGenerator import PatchGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"se_4jkpMoOhC"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ee0aQ8aXrW7M"},"source":["## Data Preprocessing\n","1. Importing CSV with labels and file paths\n","2. Label Encodeing \n","2. Train-Test split\n","3. Image processing\n","4. Saving images as numpy arrays"]},{"cell_type":"markdown","metadata":{"id":"mtP9_t6Ltc7g"},"source":["### Importing CSV\n","The csv file is generated in the data prep notebook. The file consists of all the requiered labels and patient ID. They also consist the path to the image files of all modalities."]},{"cell_type":"code","metadata":{"id":"lz5cW4fRoOhC"},"source":["# Csv import : Csv contains file paths to all modality images and 4 labels \n","df = pd.read_csv('../Data/Final_trainData_Multiclass.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIvXBvNtoOhD"},"source":["df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJeOpdXAoOhD"},"source":["df = df[df['MGMT promoter status'].isna() == False]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ntbs9lt_oOhE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qi-DQBMsoOhE"},"source":["gb = df.groupby(['Grade'])\n","gb['MGMT promoter status'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oiqL3yReoOhE"},"source":["gb = df.groupby(['Grade'])\n","gb['IDH status'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ISu-cPr5oOhF"},"source":["gb = df.groupby(['Grade'])\n","gb['IDH-1P19Q Subtype'].value_counts()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ma9gPeQbtxOb"},"source":["### LabelEncoding \n","- The labels are encoded as integers. \n","- LabelEncoder() from sklearn is used.\n","- Encoded labels are added to the dataframe as another columns\n"]},{"cell_type":"code","metadata":{"id":"n5MVhulWoOhF"},"source":["le = LabelEncoder()\n","df['Grade_Le'] = le.fit_transform(df['Grade'])\n","df['IDH_1P19Q_Le'] = le.fit_transform(df['IDH-1P19Q Subtype'])\n","df['MGMT_Le'] = le.fit_transform(df['MGMT promoter status'])\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0wjLyLqZoOhG"},"source":["df.set_index('Patient ID', inplace = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gygWoyZeoOhG"},"source":["#Label is arranged as Grade, IDHstatus, MGMT, 1P19Q\n","\n","Labels = np.c_[df['Grade_Le'], df['Class'], df['MGMT_Le'], df['IDH_1P19Q_Le']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwa2jBLPoOhG"},"source":["# df_train, df_test, Labels_train, Labels_test = train_test_split(df,Labels,test_size=0.20,random_state=9,stratify=Labels)\n","df_train = df[df['Train_Split']=='train']\n","Labels_train = Labels[df['Train_Split']=='train']\n","df_test = df[df['Train_Split']=='test']\n","Labels_test = Labels[df['Train_Split']=='test']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JuAu27IyoOhG"},"source":["print(Labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MdgQ8L0foOhH"},"source":["print('Train:')\n","print(Labels_train.value_counts())\n","\n","print('Test:')\n","print(Labels_test.value_counts())\n","\n","\"\"\"\n","G3_0 = 0\n","G3_1 = 1\n","G4_0 = 2\n","G4_1 = 3\n","\"\"\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sg8B9m7ooOhH"},"source":["tmp = df_test.iloc[0]['FLAIR']\n","img = nib.load(tmp).get_fdata()\n","print(img.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKrIouu4oOhI"},"source":["plt.imshow(img[:,:,80],cmap='gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZd5tywyoOhI"},"source":["Labels_test = np.array(Labels_test)\n","Labels_train = np.array(Labels_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yc1HMPPBr8UR"},"source":["### Image preprocessing\n","\n","Code cells below will now process our split data and give us numpy arrays.\n","The following preprocessing is done on the data:\n","1. Data is converted to numpy array\n","2. Slices are taken over the 3D image\n","3. z2 normalization is performed over each slice\n","4. A bounding box is taken over each slice for the area around the mask\n","5. The masked box is then taken over the slice and only the tumor part is considered\n","6. The bounded slices are then stacked over each other also labels are also stacked in the same order as that of the slices.\n","7. Final numpy arrays are then returned and saved for further use in model training"]},{"cell_type":"code","metadata":{"id":"UtxEAok4oOhI"},"source":["FLAIR_test_data_list, test_mask_list = get_all_subjects(df_test,'FLAIR','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')\n","T1ce_test_data_list, _ = get_all_subjects(df_test,'T1ce','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')\n","T2_test_data_list, _ = get_all_subjects(df_test,'T2','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dvk1iV9GoOhJ"},"source":["start = time.time()\n","\n","number_of_slices = 3 ## number of slices to load from each patient\n","\n","X_test_orig = []\n","Y_test_orig = []\n","mask_test_orig = []\n","modality_list = []\n","\n","for idx, msk in enumerate(test_mask_list):\n","    \n","    FLAIR_img = FLAIR_test_data_list[idx]\n","    T1ce_img = T1ce_test_data_list[idx]\n","    T2_img = T2_test_data_list[idx]    \n","    label = Labels_test[idx]\n","    \n","    print('Class: ',label,'\\tName : ',df_test.index[idx])\n","    hMin, hMax, wMin, wMax, dMin, dMax = get_roi(msk,10)    \n","    \n","    ## if you want all slices\n","    imp_slices = list(np.arange(hMin,hMax))\n","    \n","    ## important Axial slices\n","    roi_areas = [(slc,area) for slc,area in enumerate(np.sum(msk,axis=(1,2)))]\n","    roi_areas = sorted(roi_areas,key=lambda x: x[1],reverse=True)\n","    imp_slices = [x for x,_ in roi_areas[0:number_of_slices]]        \n","    \n","    for slc in imp_slices:\n","        \n","        modalities = ['FLAIR','T1ce','T2']\n","        modality_mapping = {'FLAIR':1,'T1ce':2,'T2':3}\n","        data_dict = {'FLAIR':FLAIR_img,'T1ce':T1ce_img,'T2':T2_img}\n","        \n","        for mod in modalities:\n","                        \n","            tmp_slice = data_dict[mod][slc]\n","            tmp_slice = data_dict[mod][slc][wMin:wMax,dMin:dMax]\n","            tmp_slice = resize(tmp_slice,[128,128],anti_aliasing=True)                \n","            \n","            modality_list.append(modality_mapping[mod])\n","            Y_test_orig.append(label)\n","            X_test_orig.append(tmp_slice)        \n","        \n","end = time.time()\n","print(end-start)\n","\n","X_test_orig = np.stack(X_test_orig, axis=0)\n","X_test_orig = np.expand_dims(X_test_orig, -1)\n","\n","Y_test_orig = np.stack(Y_test_orig,axis=0)\n","print('testing : ',np.unique(Y_test_orig,return_counts=True))\n","Y_test = to_categorical(Y_test_orig,num_classes=None)\n","\n","print(X_test_orig.shape,Y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TuKMdNdNoOhK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"--x9-59koOhK"},"source":["print(Y_test_orig.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P--1jFbioOhL"},"source":["print(Y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MscfezAeoOhL"},"source":["del(FLAIR_test_data_list) # save memory\n","del(T2_test_data_list) # save memory\n","del(T1ce_test_data_list) # save memory\n","del(test_mask_list) # save memory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpTlHlyBoOhL"},"source":["FLAIR_train_data_list, train_mask_list = get_all_subjects(df_train,'FLAIR','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')\n","T1ce_train_data_list, _ = get_all_subjects(df_train,'T1ce','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')\n","T2_train_data_list, _ = get_all_subjects(df_train,'T2','Mask',label_values=[1,2,4],transpose_axes=[2,0,1],norm_type='zscore')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p9XiWSpFoOhM"},"source":["start = time.time()\n","\n","number_of_slices = 20\n","\n","X_train_orig = []\n","Y_train_orig = []\n","modality_list = []\n","\n","for idx, msk in enumerate(train_mask_list):\n","    \n","#     FLAIR_img = FLAIR_train_data_list[idx]\n","#     T1ce_img = T1ce_train_data_list[idx]\n","#     T2_img = T2_train_data_list[idx]    \n","    label = Labels_train[idx]\n","    \n","    print('Class: ',label,'\\tName : ',df_train.index[idx])\n","    hMin, hMax, wMin, wMax, dMin, dMax = get_roi(msk,10)    \n","    \n","    ## important Axial slices\n","    roi_areas = [(slc,area) for slc,area in enumerate(np.sum(msk,axis=(1,2)))]\n","    roi_areas = sorted(roi_areas,key=lambda x: x[1],reverse=True)\n","    imp_slices = [x for x,_ in roi_areas[0:number_of_slices]]\n","    \n","    for slc in imp_slices:\n","        \n","        modalities = ['FLAIR','T1ce','T2']\n","        modality_mapping = {'FLAIR':1,'T1ce':2,'T2':3}\n","        data_dict = {'FLAIR':FLAIR_img,'T1ce':T1ce_img,'T2':T2_img}\n","        \n","        for mod in modalities:\n","                        \n","            tmp_slice = data_dict[mod][slc]\n","            tmp_slice = data_dict[mod][slc][wMin:wMax,dMin:dMax]\n","            tmp_slice = resize(tmp_slice,[128,128],anti_aliasing=True)                \n","            \n","            modality_list.append(modality_mapping[mod])\n","            Y_train_orig.append(label)\n","            X_train_orig.append(tmp_slice)        \n","        \n","end = time.time()\n","print(end-start)\n","\n","X_train_orig = np.stack(X_train_orig, axis=0)\n","X_train_orig = np.expand_dims(X_train_orig, -1)\n","\n","Y_train_orig = np.stack(Y_train_orig,axis=0)\n","print('training : ',np.unique(Y_train_orig,return_counts=True))\n","Y_train = to_categorical(Y_train_orig,num_classes=None)\n","\n","print(X_train_orig.shape,Y_train.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YZ91qSgoOhM"},"source":["del(FLAIR_train_data_list) # save memory\n","del(T2_train_data_list) # save memory\n","del(T1ce_train_data_list) # save memory\n","del(train_mask_list) # save memory"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POoaFgRhoOhM"},"source":["x_train = X_train_orig\n","x_test = X_test_orig\n","y_train = Y_train_orig\n","y_test = Y_test_orig\n","\n","print(x_train.shape,y_train.shape)\n","print(x_test.shape,y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"audOzA0GoOhN"},"source":["# Saving single modality images as numpy array\n","\n","np.save('../Data/X_train_ML_3.npy',x_train)\n","np.save('../Data/Y_train_ML_3.npy',y_train)\n","np.save('../Data/X_test_ML_3.npy',x_test)\n","np.save('../Data/Y_test_ML_3.npy',y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFPbomgvoOhN"},"source":["# Splitting modalities and assignning to individual arrays\n","x_train_FLAIR = x_train[np.arange(0,4500,3),:,:,0]\n","x_train_T1ce = x_train[np.arange(1,4500,3),:,:,0]\n","x_train_T2 = x_train[np.arange(2,4500,3),:,:,0]\n","\n","x_test_FLAIR = x_test[np.arange(0,171,3),:,:,0]\n","x_test_T1ce = x_test[np.arange(1,171,3),:,:,0]\n","x_test_T2 = x_test[np.arange(2,171,3),:,:,0]\n","\n","print(x_train_FLAIR.shape,x_train_T1ce.shape, x_train_T2.shape)\n","print(x_test_FLAIR.shape,x_test_T1ce.shape,x_test_T2.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"puR0RvFwoOhN"},"source":["# Stacking the 3 modalites on each other in the order FLAIR, T1ce, T2\n","x_train = np.stack([x_train_FLAIR,x_train_T1ce, x_train_T2],axis=-1)\n","x_test = np.stack([x_test_FLAIR,x_test_T1ce, x_test_T2],axis=-1)\n","print(x_train.shape,x_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0uW56M_oOhO"},"source":["# Arranging labels same as images\n","y_train = y_train[np.arange(0,len(y_train),3)]\n","y_test = y_test[np.arange(0,len(y_test),3)]\n","print(y_train.shape,y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2_M_GrcoOhO"},"source":["# Saving the stacked models\n","np.save('../Data/X_train_ML_3mod.npy',x_train)\n","np.save('../Data/Y_train_ML_3mod.npy',y_train)\n","np.save('../Data/X_test_ML_3mod.npy',x_test)\n","np.save('../Data/Y_test_ML_3mod.npy',y_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5GaODnP4vHX1"},"source":["## Datagen"]},{"cell_type":"code","metadata":{"id":"gShCAkJFoOhP"},"source":["x_train = np.load('../Data/X_train_ML_2.npy')\n","y_train = np.load('../Data/Y_train_ML_2.npy')\n","x_test = np.load('../Data/X_test_ML_2.npy')\n","y_test = np.load('../Data/Y_test_ML_2.npy')\n","\n","\n","\n","print(x_train.shape,y_train.shape)\n","print(x_test.shape,y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieSsmWTioOhP"},"source":["plt.imshow(x_test[10][:,:,0], cmap = 'gray')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TqzNrTGToOhP"},"source":["print(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dCqgq66MoOhQ"},"source":["bkp_X_train = np.copy(x_train)\n","bkp_Y_train = np.copy(y_train)\n","bkp_X_test = np.copy(x_test)\n","bkp_Y_test = np.copy(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x815Fr5poOhQ"},"source":["\"\"\"def grayscale_to_3channel(x):\n","    x = np.squeeze(x)\n","    return np.stack([x,x,x],axis=-1)\n","\n","X_train = grayscale_to_3channel(bkp_X_train)\n","X_test = grayscale_to_3channel(bkp_X_test)\n","\n","input_shape = X_train.shape[1:]\n","print(input_shape)\n","\n","# X_train = preprocess_input(X_train)\n","# X_test = preprocess_input(X_test)\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4611I0c1oOhQ"},"source":["del(bkp_X_test)\n","del(bkp_X_train)\n","del(bkp_Y_test)\n","del(bkp_Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hBiDojY0oOhS"},"source":["datagen = ImageDataGenerator(\n","    width_shift_range = [0.2, 0.3],\n","    height_shift_range = [0.2, 0.3],    \n","    vertical_flip = True,\n","    horizontal_flip = True,\n","    rotation_range=15,\n","    zoom_range=[0.5,1.0],\n","    channel_shift_range=0.2\n","#     fill_mode = 'constant',\n","#     cval=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uR2YCeD5oOhT"},"source":["from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n","\n","y_integers = np.argmax(y_train, axis=1)\n","class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n","train_sample_weights = compute_sample_weight('balanced',y_train)\n","train_class_weights = dict(enumerate(class_weights))\n","\n","print(train_class_weights)\n","\n","y_integers = np.argmax(y_test, axis=1)\n","class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n","test_sample_weights = compute_sample_weight('balanced',y_test)\n","test_class_weights = dict(enumerate(class_weights))\n","\n","print(test_class_weights)"]},{"cell_type":"code","metadata":{"id":"YNyeuhPJoOhT"},"source":["y_test[:,1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQQRAbyDoOhT"},"source":["y_test[:,0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ps7kJlrVoOhU"},"source":["# Custom generator function to map the 4 labels to the inputs\n","# This is necessary as we have 4 outputs for our model due to 4 tasks\n","\n","def generator_wrapper(generator):\n","    for batch_x,batch_y in generator:\n","        yield (batch_x,[batch_y[:,i] for i in range(4)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svBSAsKooOhU"},"source":["batch_size = 64\n","\n","train_datagen = datagen.flow(x_train,y_train,\n","                             batch_size=batch_size,\n","                             shuffle=True,                             \n","                            )\n","\n","\n","test_datagen = ImageDataGenerator().flow(x_test,y_test,batch_size=batch_size,\n","                                         shuffle=True)\n","\n","#test_datagen = datagen.flow(X_test,y_test,batch_size=batch_size,\n","#                                         shuffle=True)\n","\n","print(len(train_datagen),len(test_datagen))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XcFIPEgAoOhU"},"source":["batch = test_datagen.next()\n","subject = np.random.randint(0,len(batch[1]))\n","print(subject,batch[1][subject])\n","\n","plt.figure()\n","#plt.subplot(1,2,1)\n","plt.imshow(batch[0][subject,:,:,0],cmap='gray')\n","\n","print(np.mean(batch[0])0.,np.std(batch[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5gysFHvJoOhU"},"source":["test_datagen.reset()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ObF_Q4rvwhS"},"source":["## Model Design\n","1. fire_module from squeeze net architeture (paper : https://arxiv.org/abs/1602.07360)\n","2. Multitask model design with all the branches."]},{"cell_type":"code","metadata":{"id":"9WlB7TWroOhV"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","# import models\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications import ResNet50,DenseNet169,InceptionResNetV2,VGG16\n","from tensorflow.keras.layers import Flatten,concatenate,Input,Activation, GlobalAveragePooling2D,GlobalMaxPooling2D, Dense, Conv2D, MaxPool2D, Dropout, BatchNormalization, Lambda,AveragePooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zNVThh9FoOhV"},"source":["# Squeezenet fireblock module design\n","\n","sq1x1 = \"squeeze1x1\"\n","exp1x1 = \"expand1x1\"\n","exp3x3 = \"expand3x3\"\n","relu = \"relu_\"\n","\n","def fire_module(x, fire_id, squeeze=16, expand=64):\n","    s_id = 'fire' + str(fire_id) + '/'\n","\n","    if K.image_data_format() == 'channels_first':\n","        channel_axis = 1\n","    else:\n","        channel_axis = 3\n","    \n","    x = Conv2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n","    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n","\n","    left = Conv2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n","    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n","\n","    right = Conv2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n","    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n","\n","    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYkNSFyVoOhV"},"source":["def res50_model(ip):\n","    \n","    # Importing the resnet50 architecture with imagenet weights from the keras applications \n","\n","    K_res50 = keras.applications.ResNet50(input_tensor = ip, include_top=False, weights='imagenet', input_shape=[128, 128, 3])\n","  \n","    K_res50_l = K_res50.layers[-10]\n","    x1 = K_res50.output # Taking the output skipping the last resnet block\n","    x = K_res50_l.output # Taking the output from the resnet module\n","    \n","    # Deciding the trainablity of the layers\n","    for layer in K_res50.layers[12:50]:\n","        layer.trainable = False \n","    \n","    x = MaxPool2D(pool_size=(2, 2), strides=None, padding='same', name='CMaxPool')(x)\n","    \n","    #Grade Prediction layers\n","    \n","    output1 = fire_module(x, fire_id='op1_0', squeeze=64, expand=256)\n","    output1 = fire_module(output1, fire_id='op1_1', squeeze=64, expand=128)\n","    output1 = keras.layers.BatchNormalization(name='BatchNorm_op1_0')(output1)\n","    output1 = keras.layers.GlobalAveragePooling2D(name='gap_op1')(output1)\n","    #output1 = keras.layers.BatchNormalization(name='BatchNorm_op1_1')(output1)\n","    output1 = keras.layers.Dropout(0.3,name='Dropout_output1')(output1)\n","    #output1 = keras.layers.Dense(8, activation='sigmoid', name='output1_Dense1')(output1)\n","    output1 = keras.layers.Dense(1, activation='sigmoid', name='output1')(output1)\n","    \n","    #IDH status prediction layers\n","    \n","    #output2 = Conv2D(256, (1, 1), padding='valid', name = 'conv_op2')(x1)\n","    #output2 = keras.layers.BatchNormalization(name='BatchNorm_op2_0')(output2)\n","    output2 = fire_module(x1, fire_id='op2_0', squeeze=64, expand=256)\n","    #output2 = keras.layers.BatchNormalization(name='BatchNorm_op2_1')(output2)\n","    #output2 = fire_module(output2, fire_id='op2_1', squeeze=4, expand=8)\n","    output2 = keras.layers.GlobalMaxPooling2D(name='gmp_op2')(output2)\n","    output2 = keras.layers.BatchNormalization(name='BatchNorm_op2')(output2)\n","    output2 = keras.layers.Dropout(0.3,name='Dropout_output2')(output2)\n","    output2 = keras.layers.Dense(256, name='output2_Dense2')(output2)\n","    output2 = keras.layers.LeakyReLU(alpha=0.3)(output2)\n","    output2 = keras.layers.Dropout(0.4,name='Dropout_1_output2')(output2)\n","    \n","    #output2 = keras.layers.Dense(2, activation='sigmoid', name='output2_0')(output2)\n","    output2 = keras.layers.Dense(1, activation = 'sigmoid', name = 'output2')(output2)\n","    \n","    #MGMT prediction layers\n","    \n","    output3 = fire_module(x, fire_id='op3', squeeze=64, expand=128)\n","    output3 = keras.layers.BatchNormalization(name='BatchNorm_op3_0')(output3)\n","    output3 = fire_module(output3, fire_id='op3_1', squeeze=16, expand=32)\n","    output3 = keras.layers.GlobalMaxPooling2D(name='gap_op3')(output3)\n","    output3 = keras.layers.Dropout(0.3,name='Dropout_output3')(output3)\n","    #output3 = keras.layers.Dense(8, activation='sigmoid', name='output3_Dense2')(output3)\n","    output3 = keras.layers.Dense(1, activation='sigmoid', name='output3')(output3)\n","    \n","    #1P19q prediction layers\n","    \n","    output4_left = fire_module(x, fire_id='op4_0', squeeze=64, expand=128)\n","    output4_left = keras.layers.BatchNormalization(name='BatchNorm_op4_0')(output4_left)\n","    output4_left = keras.layers.Dropout(0.3,name='Dropout_output4_0')(output4_left)\n","    output4_left = fire_module(output4_left, fire_id='op4_1', squeeze=32, expand=64)\n","    output4_left = keras.layers.GlobalAveragePooling2D(name='gap_op4')(output4_left)\n","    output4_left = keras.layers.Dropout(0.3,name='Dropout_output4_1')(output4_left)\n","    #output4_left = keras.layers.Dense(8, activation='sigmoid', name='output4_l_Dense1')(output4_left)\n","    output4_left = keras.layers.Dense(2, activation='sigmoid', name='output4_l_Dense2')(output4_left)\n","    \n","    output4_right = keras.layers.Dense(2, activation='sigmoid', name='buffer_op2_op4')(output2)\n","    \n","    output4 = concatenate([output4_left, output4_right], axis=-1, name='output4_concat')\n","    output4 = keras.layers.Dense(1, activation='sigmoid', name='output4')(output4)\n","    \n","    return [output1, output2, output3, output4]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xsPQaD-IoOhV"},"source":["ip1=Input(shape=(128,128,3))\n","res50=Model(inputs=ip1,outputs=res50_model(ip1))\n","res50.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d3hZn8nvoOhW"},"source":["# Visualising the model\n","from tensorflow.keras.utils import plot_model\n","plot_model(res50, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PrD_J2e2Bx9G"},"source":["\"\"\"\n","Defining custom loss function\n","For the missing labels value needs to be set to -1 which is the mask value.\n","This loss function masks the missing labels and thus no training happens.\n","\"\"\"\n","mask_value = -1\n","def masked_loss_function(y_true, y_pred):\n","    mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n","    return K.binary_crossentropy(y_true * mask, y_pred * mask)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lYPWnBXIoOhW"},"source":["adam = keras.optimizers.Adam(learning_rate=0.000003)\n","\n","res50.compile(adam,['binary_crossentropy','binary_crossentropy', masked_loss_function, masked_loss_function],metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gR6Rk_YRoOhW"},"source":["train_steps = len(train_datagen)\n","test_steps = len(test_datagen)\n","print(train_steps, test_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-kfUO88oOhW"},"source":["filename=os.path.join('logs','TCGA_res50_MT_3mod.csv')\n","filepath=os.path.join('weights','TCGA_res50_MT_3mod.hdf5')\n","csv_log = CSVLogger(filename, separator=',', append=True)\n","checkpoint = ModelCheckpoint(filepath, monitor='val_output1_acc', verbose=1, save_best_only=True)\n","rl = ReduceLROnPlateau(monitor='val_output1_acc',patience=5,min_delta=0.001,cooldown=5,factor=0.1)\n","tb = TensorBoard('./logs',histogram_freq=0)\n","callbacks_list = [csv_log,\n","                  checkpoint,\n","                  rl,\n","                  tb\n","                 ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ec8IImEooOhX"},"source":["if os.path.exists('weights/TCGA_res50_MT_10.hdf5'):\n","    res50.load_weights(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FrxZP4QPoOhX"},"source":["print(filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n59GqlLxoOhX"},"source":["tf.config.experimental.list_physical_devices('GPU')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9cjsNUCeoOhX"},"source":["epochs = 500\n","res50_H = res50.fit(generator_wrapper(train_datagen), steps_per_epoch=train_steps, epochs=epochs,\n","                    verbose = 1,validation_data=generator_wrapper(test_datagen),validation_steps=test_steps,\n","                    callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ZI3UPo4oOhY"},"source":["# create a new figure for the accuracies\n","accuracyNames = [\"output1_acc\", \"output2_acc\", \"output3_acc\", 'output4_acc']\n","plt.style.use(\"ggplot\")\n","(fig, ax) = plt.subplots(4, 1, figsize=(8, 8))\n","# loop over the accuracy names\n","for (i, l) in enumerate(accuracyNames):\n","    # plot the loss for both the training and validation data\n","    ax[i].set_title(\"Accuracy for {}\".format(l))\n","    ax[i].set_xlabel(\"Epoch #\")\n","    ax[i].set_ylabel(\"Accuracy\")\n","    ax[i].plot(np.arange(0, epochs), res50_H.history[l], label=l)\n","    ax[i].plot(np.arange(0, epochs), res50_H.history[\"val_\" + l],\n","        label=\"val_\" + l)\n","    ax[i].legend()\n","# save the accuracies figure\n","plt.tight_layout()\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IehyTNy1oOhZ"},"source":["lossNames = [\"output1_loss\", \"output2_loss\", \"output3_loss\", 'output4_loss']\n","plt.style.use(\"ggplot\")\n","(fig, ax) = plt.subplots(4, 1, figsize=(8, 8))\n","# loop over the loss names\n","for (i, l) in enumerate(lossNames):\n","    # plot the loss for both the training and validation data\n","    ax[i].set_title(\"loss for {}\".format(l))\n","    ax[i].set_xlabel(\"Epoch #\")\n","    ax[i].set_ylabel(\"loss\")\n","    ax[i].plot(np.arange(0, epochs), res50_H.history[l], label=l)\n","    ax[i].plot(np.arange(0, epochs), res50_H.history[\"val_\" + l],\n","        label=\"val_\" + l)\n","    ax[i].legend()\n","# save the accuracies figure\n","plt.tight_layout()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dvIY1kwToOhZ"},"source":["#saving the model with weights\n","res50.save('../Model/TCGA_Multitask_res50_4pred_2.h5')\n","\n","res50.save_weights('weights/TCGA_Multitask_res50_4pred_2.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"viC03U5WC5Eo"},"source":["## Post training analysis"]},{"cell_type":"code","metadata":{"id":"FQzl7bcuoOhZ"},"source":["_test_data, _test_labels = test_datagen.__getitem__(np.random.randint(0,len(test_datagen)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qS-GKicoOha"},"source":["## evaluate the model and predict on testing data\n","print('Evaluate')\n","a=res50.evaluate(generator_wrapper(test\n","                                   _datagen),batch_size=batch_size,verbose=1,steps = 1)\n","print('val_loss , val_acc: ', a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8A77oV_5oOha"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","from sklearn.metrics import (accuracy_score, classification_report,\n","                              confusion_matrix, roc_auc_score, roc_curve)\n","\n","def get_roc(y_true, y_pred, positive_class_index=0):\n","    y_pred = np.copy(y_pred)[:, positive_class_index]\n","    return {'auroc': roc_auc_score(y_true, y_pred), 'roc': roc_curve(y_true, y_pred)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0c-yePQXoOha"},"source":["y_pred_proba = res50.predict_generator(test_datagen,verbose=1) \n","y_true = y_test\n","y_pred = y_pred_proba"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B257vlIHoOha"},"source":["len(y_pred_proba[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zElGm8GXoOhb"},"source":["y_pred = np.array(y_pred).reshape(-1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H3ag-hzXoOhb"},"source":["y_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"omgcL7gGoOhb"},"source":["y_pred = np.array(y_pred).reshape(152,4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CgwmkakCoOhb"},"source":["print(y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ea2cLNCDoOhe"},"source":["print(classification_report(y_true[:,0],y_pred[:,0].round())) # classification report for Grade"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPdVp-F4oOhe"},"source":["print(classification_report(y_true[:,1],y_pred[:,1].round())) # classification report for IDH"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7zsPAB5oOhe"},"source":["print(classification_report(y_true[:,2],y_pred[:,2].round())) # classification report for MGMT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7lTuI3sroOhf"},"source":["print(classification_report(y_true[:,3],y_pred[:,3].round())) # classification report for 1p19q"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smty5cp_oOhf"},"source":["from sklearn.metrics import roc_curve, auc\n","from sklearn.multiclass import OneVsRestClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZyQR_lBoOhf"},"source":["n_classes = 4\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_true[:,i],y_pred[:,i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot of a ROC curve for a specific class\n","for i in range(n_classes):\n","    plt.figure()\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n","    #plt.plot([0, 1], [0, 1], 'k--')\n","    #plt.xlim([0.0, 1.0])\n","    #plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver operating characteristic example')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()"],"execution_count":null,"outputs":[]}]}