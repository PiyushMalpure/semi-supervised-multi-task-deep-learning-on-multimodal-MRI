{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"tf2_env","language":"python","name":"tf2_env"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"colab":{"name":"HR_CAMS_Multitask.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Da-QIULesIRG"},"source":["# HR-CAM for multitask model\n","This file contains the HR-CAM model and code to get the HR-CAMs for all the 4 tasks of multitask.\n","\n","PS. Highly recommended to read HR-CAMs papaer if not yet done\n"]},{"cell_type":"code","metadata":{"id":"Th-PxdtamVzj"},"source":["# importing as usual\n","import pandas as pd\n","import os\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","\n","from tensorflow import keras\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","\n","from tensorflow.keras import backend as K\n","import nibabel as nib\n","import cv2\n","import time\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n","from tensorflow.keras.utils import to_categorical\n","\n","from prep_data import get_roi, get_all_subjects, get_subject, get_subject_list, pad_to_shape, remove_padding\n","from PatchGenerator import PatchGenerator\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","import models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eI-Oc9_HmVzt"},"source":["from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard\n","# import models\n","from tensorflow.keras import Model\n","from tensorflow.keras.applications import ResNet50,DenseNet169,InceptionResNetV2,VGG16\n","from tensorflow.keras.layers import Conv2DTranspose\n","\n","from tensorflow.keras.layers import Add, MaxPool2D, Flatten,concatenate,Input,Activation\n","from tensorflow.keras.layers import GlobalAveragePooling2D,GlobalMaxPooling2D, Dense, Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Lambda, AveragePooling2D"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYP10PzmmVzu"},"source":["# Importing data\n","\n","x_train = np.load('../Data/X_train_ML_3.npy')\n","y_train = np.load('../Data/Y_train_ML_3.npy')\n","x_test = np.load('../Data/X_test_ML_3.npy')\n","y_test = np.load('../Data/Y_test_ML_3.npy')\n","\n","\n","print(x_train.shape,y_train.shape)\n","print(x_test.shape,y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qUfOvlnomVzu"},"source":["bkp_X_train = np.copy(x_train)\n","bkp_Y_train = np.copy(y_train)\n","bkp_X_test = np.copy(x_test)\n","bkp_Y_test = np.copy(y_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bZNKVqwJmVzv"},"source":["def grayscale_to_3channel(x):\n","    x = np.squeeze(x)\n","    return np.stack([x,x,x],axis=-1)\n","\n","X_train = grayscale_to_3channel(bkp_X_train)\n","X_test = grayscale_to_3channel(bkp_X_test)\n","\n","input_shape = X_train.shape[1:]\n","print(input_shape)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vdeNM9pXmVzv"},"source":["del(bkp_X_test)\n","del(bkp_X_train)\n","del(bkp_Y_test)\n","del(bkp_Y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMKITmFo8GOz"},"source":["# Importing 3 modality stacked data\n","x_train = np.load('../Data/X_train_ML_3mod.npy')\n","y_train = np.load('../Data/Y_train_ML_3mod.npy')\n","x_test = np.load('../Data/X_test_ML_3mod.npy')\n","y_test = np.load('../Data/Y_test_ML_3mod.npy')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2nLxrcXmVzw"},"source":["datagen = ImageDataGenerator(\n","    width_shift_range = [0.2, 0.3],\n","    height_shift_range = [0.2, 0.3],    \n","    vertical_flip = True,\n","    horizontal_flip = True,\n","    rotation_range=15,\n","    zoom_range=[0.5,1.0],\n","    #channel_shift_range=0.2\n","#     fill_mode = 'constant',\n","#     cval=0,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xOAjGwj4mVzw"},"source":["def generator_wrapper(generator):\n","    for batch_x,batch_y in generator:\n","        yield (batch_x,[batch_y[:,i] for i in range(4)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cP9gtoVtmVzw"},"source":["batch_size = 8\n","\n","train_datagen = datagen.flow(X_train,y_train,\n","                             batch_size=batch_size,\n","                             shuffle=True,                             \n","                            )\n","\n","\n","test_datagen = ImageDataGenerator().flow(X_test,y_test,batch_size=batch_size,\n","                                         shuffle=True)\n","\n","#test_datagen = datagen.flow(X_test,y_test,batch_size=batch_size,\n","#                                         shuffle=True)\n","\n","print(len(train_datagen),len(test_datagen))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BlEjZ69BmVzz"},"source":["new_model.save('../Model/TCGA_miccai_trained_2.h5')\n","\n","new_model.save_weights('weights/TCGA_miccai_trained_2.hdf5')"]},{"cell_type":"code","metadata":{"id":"R4Um3WVzmVz0"},"source":["# importing the trained Multitask-model\n","new_model = keras.models.load_model('../Model/TCGA_miccai_trained_2.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5F6bU_-6mVz0"},"source":["#loading file weights just to be sure\n","filepath_init = 'weights/TCGA_miccai_trained_2.hdf5'\n","new_model.load_weights(filepath_init)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIDrB_zimVz0"},"source":["# Adjusting trainability of layers \n","# Making all the layers non-trainable\n","for layer in new_model.layers:\n","    layer.trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zmnWfnY3mVz1"},"source":["new_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZiSDnapsmVz1"},"source":["def new_model_hr(ip):\n","    \"\"\"\n","    This code defines the HR-model with 4 layers from each task's branch\n","    \n","    \"\"\"\n","    model_hr = new_model\n","    \n","    for layer in new_model.layers:\n","        layer.trainable=False\n","    for layer in model_hr.layers:\n","        layer.trainable=False\n","        \n","    imp_layer1_ids = ['fireop1_0/squeeze1x1','fireop1_0/squeeze1x1','fireop1_0/squeeze1x1','fireop1_0/expand3x3']\n","    out1_1 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer1_ids[0]).output)             \n","    out1_2 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer1_ids[1]).output)             \n","    out1_3 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer1_ids[2]).output)            \n","    out1_4 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer1_ids[3]).output)\n","    \n","    merge1 = concatenate([out1_1,out1_2,out1_3,out1_4],axis=-1, name='merge1')               \n","    op1 = Dense(1,activation='sigmoid',name='dense_hr_1')(merge1)    \n","\n","\n","    imp_layer2_ids = ['fireop2_0/expand3x3','fireop2_0/expand1x1','fireop2_0/squeeze1x1','fireop2_0/squeeze1x1'] \n","    out2_1 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer2_ids[0]).output)             \n","    out2_2 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer2_ids[1]).output)             \n","    out2_3 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer2_ids[2]).output)            \n","    out2_4 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer2_ids[3]).output)\n","    \n","    merge2 = concatenate([out2_1,out2_2,out2_3,out2_4],axis=-1, name='merge2')               \n","    op2 = Dense(1,activation='sigmoid',name='dense_hr_2')(merge2)   \n","\n","    imp_layer3_ids = ['fireop3/expand3x3','fireop3/expand1x1','fireop3/squeeze1x1','fireop3_1/expand3x3'] \n","    out3_1 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer3_ids[0]).output)             \n","    out3_2 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer3_ids[1]).output)             \n","    out3_3 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer3_ids[2]).output)            \n","    out3_4 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer3_ids[3]).output)\n","    \n","    merge3 = concatenate([out3_1,out3_2,out3_3,out3_4],axis=-1, name='merge3')              \n","    op3 = Dense(1,activation='sigmoid',name='dense_hr_3')(merge3)   \n","\n","    imp_layer4_ids = ['fireop4_0/expand3x3','fireop4_0/expand1x1','fireop4_0/squeeze1x1','fireop4_1/expand3x3'] \n","    out4_1 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer4_ids[0]).output)             \n","    out4_2 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer4_ids[1]).output)             \n","    out4_3 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer4_ids[2]).output)            \n","    out4_4 = GlobalAveragePooling2D()(model_hr.get_layer(imp_layer4_ids[3]).output)\n","    \n","    merge4 = concatenate([out4_1,out4_2,out4_3,out4_4],axis=-1, name='merge4')               \n","    op4 = Dense(1,activation='sigmoid',name='dense_hr_4')(merge4)    \n","\n","    \n","    return [op1, op2, op3, op4]\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRQdJRGGmVz2"},"source":["#ip = np.zeros((1,128,128,3)).astype('float32')\n","hr_model=  Model(inputs = new_model.inputs, outputs = new_model_hr(new_model.inputs))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svn4mpvzmVz3"},"source":["hr_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQnolAtRmVz3"},"source":["hr_filename=os.path.join('logs','TCGA_hr.csv')\n","hr_filepath=os.path.join('weights','TCGA_hr.hdf5')\n","hr_csv_log = CSVLogger(hr_filename, separator=',', append=True)\n","hr_checkpoint = ModelCheckpoint(hr_filepath, monitor='val_dense_hr_1_acc', verbose=1, save_best_only=True)\n","hr_rl = ReduceLROnPlateau(monitor='val_loss',patience=10,min_delta=0.001,cooldown=5,)\n","hr_tb = TensorBoard('./logs',histogram_freq=0)\n","hr_callbacks_list = [hr_csv_log,\n","                  hr_checkpoint,\n","                  #hr_rl,\n","                  hr_tb,\n","                 ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BGK-aBr4mVz3"},"source":["hr_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0003),loss=['binary_crossentropy','binary_crossentropy','binary_crossentropy','binary_crossentropy' ], metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DPF3kUHzmVz4"},"source":["# Loading weights agaiin from previous model \n","hr_model.load_weights(filepath_init, by_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHZXEuNUmVz4"},"source":["train_steps = len(train_datagen)\n","test_steps = len(test_datagen)\n","print(train_steps, test_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"pWifAgV5mVz4"},"source":["# Training the HR model\n","epochs = 20\n","HR_H = hr_model.fit(generator_wrapper(train_datagen), steps_per_epoch=train_steps, epochs=epochs,\n","                    verbose = 1,validation_data=generator_wrapper(test_datagen),validation_steps=test_steps,callbacks=hr_callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"29qKn0Z_mVz5"},"source":["hr_model.load_weights(hr_filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1cUktx98mVz5"},"source":["_test_data, _test_labels = test_datagen.__getitem__(np.random.randint(0,len(test_datagen)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wAtsezWBmVz5"},"source":["## evaluate the model and predict on testing data\n","print('Evaluate')\n","a=hr_model.evaluate(generator_wrapper(test_datagen),batch_size=batch_size,verbose=1,steps = 1)\n","print('val_loss , val_acc: ', a)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2D0XqWPNmVz7"},"source":["def get_heatmaps_hr(model, image, layer_ids, weight_layer=None, classes=None, h=None, w=None):\n","    #Function to compute the final hr_cams from the trained hr_cam model\n","    #model : Trained hr_cam model\n","    #image : images to compute hr_cams for\n","    #layer_ids : layer ids of important layers used in the hr_cams\n","    #weight_layer : layer of the model from which the weights need to be computed set to -1th layer by default\n","    #classes : number of classes \n","    #h = height of image, should be specified if output height needs to be different than the input image\n","    #w = width of image, should be specified if output width needs to be different than the input image\n","    \n","    if weight_layer is None:\n","        weight_layer = model.get_layer(index=-1)\n","    heatmaps = []\n","    wts = []\n","    \n","    h = image.shape[-3] if h == None else h\n","    w = image.shape[-2] if w == None else w\n","    \n","    if classes is None:\n","        pred = model.predict(image)\n","        classes = pred[0]\n","    \n","    imp_layer_0 = model.get_layer(layer_ids[0])\n","    imp_layer_1 = model.get_layer(layer_ids[1])\n","    imp_layer_2 = model.get_layer(layer_ids[2])\n","    imp_layer_3 = model.get_layer(layer_ids[3])\n","   \n","    hmp_model = Model(inputs=model.inputs, outputs=[imp_layer_0.output,\n","                                                    imp_layer_1.output,\n","                                                    imp_layer_2.output,\n","                                                    imp_layer_3.output\n","                                                    ])\n","    \n","    out = hmp_model.predict(x=image,verbose=1,batch_size=int(batch_size/4))\n","    weights = model.get_layer(weight_layer).get_weights()[0] # [0] is for wts [1] for bias\n"," \n","    for i in range(len(classes)):\n","        \n","        print('Image no : ',i)\n","                \n","        class_idx = classes[i]           \n","        class_w = weights\n","\n","        i_idx = 0\n","        f_idx = imp_layer_0.output_shape[-1]\n","        hmp_0 = K.sum(out[0][i:i+1] * class_w[i_idx:f_idx,0], axis=-1)\n","        hmp_0 = K.expand_dims(hmp_0, axis=-1)\n","        hmp_0 = K.eval(tf.image.resize_bilinear(hmp_0, [h, w]))\n","\n","        i_idx = imp_layer_0.output_shape[-1]\n","        f_idx = i_idx + imp_layer_1.output_shape[-1]\n","        hmp_1 = K.sum(out[1][i:i+1] * class_w[i_idx:f_idx,0], axis=-1)\n","        hmp_1 = K.expand_dims(hmp_1, axis=-1)\n","        hmp_1 = K.eval(tf.image.resize_bilinear(hmp_1, [h, w]))\n","\n","        i_idx = imp_layer_1.output_shape[-1]\n","        f_idx = i_idx + imp_layer_2.output_shape[-1]\n","        hmp_2 = K.sum(out[2][i:i+1] * class_w[i_idx:f_idx,0], axis=-1)\n","        hmp_2 = K.expand_dims(hmp_2, axis=-1)\n","        hmp_2 = K.eval(tf.image.resize_bilinear(hmp_2, [h, w]))\n","\n","        i_idx = imp_layer_2.output_shape[-1]\n","        f_idx = i_idx + imp_layer_3.output_shape[-1]\n","        hmp_3 = K.sum(out[3][i:i+1] * class_w[i_idx:f_idx,0], axis=-1)\n","        hmp_3 = K.expand_dims(hmp_3, axis=-1)\n","        hmp_3 = K.eval(tf.image.resize_bilinear(hmp_3, [h, w]))\n","\n","        \n","        hmp = np.squeeze(hmp_0+hmp_1+hmp_2+hmp_3)\n","        heatmaps.append(hmp)\n","        wts.append(class_w)    \n","    \n","    return np.stack(heatmaps,axis = 0), classes, np.stack(class_w,axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jv7h-YvKmVz8"},"source":["imp_layer1_ids = ['fireop1_0/squeeze1x1','fireop1_0/squeeze1x1','fireop1_0/squeeze1x1','fireop1_0/expand3x3']\n","imp_layer2_ids = ['fireop2_0/expand3x3','fireop2_0/expand1x1','fireop2_0/squeeze1x1','fireop2_0/squeeze1x1']\n","imp_layer3_ids = ['fireop3/expand3x3','fireop3/expand1x1','fireop3/squeeze1x1','fireop3_1/expand3x3'] \n","imp_layer4_ids = ['fireop4_0/expand3x3','fireop4_0/expand1x1','fireop4_0/squeeze1x1','fireop4_1/expand3x3']\n","output_layer_ids = ['dense_hr_1', 'dense_hr_2', 'dense_hr_3', 'dense_hr_2']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EYD6H1tQmVz8"},"source":["# selecting images to get the Cams for\n","_x = np.copy(X_test)[[2, 54, 28, 98, 140, 20, 89],:]\n","_y = np.copy(y_test)[[2, 54, 28, 98, 140, 20, 89]]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVqAH3OimVz9"},"source":["print('Calculating HR hmp')\n","hr_hmp_0, hr_pred_0, hr_w1_0 = get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer1_ids, weight_layer=output_layer_ids[0] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BHbG1XJGmVz9"},"source":["inv_hr_hmp_0, inv_hr_pred_0, inv_hr_w1_0 =get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer1_ids, weight_layer=output_layer_ids[0] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6mRMaFYMmVz-"},"source":["for i in range(len(hr_hmp_0)):\n","    hr_hmp_0[i] = np.maximum(hr_hmp_0[i],0,hr_hmp_0[i])\n","    hr_hmp_0[i] = (hr_hmp_0[i]-hr_hmp_0[i].min())/(hr_hmp_0[i].max()-hr_hmp_0[i].min())\n","for i in range(len(inv_hr_hmp_0)):\n","    hr_hmp_0[i] = np.maximum(hr_hmp_0[i],0,hr_hmp_0[i])\n","    inv_hr_hmp_0[i] = (inv_hr_hmp_0[i]-inv_hr_hmp_0[i].min())/(inv_hr_hmp_0[i].max()-inv_hr_hmp_0[i].min())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HmyHsQq-mVz-"},"source":["#GRADE HR_CAMS\n","\n","idx = 6#np.random.randint(0,len(_y))\n","x_img = np.copy(_x[idx])\n","y_img = np.copy(_y[idx])\n","print('Idx: ',idx,' Class: ',y_img)\n","#print('Predicted class - Base model: ',res_pred[idx],' HR_Cam: ',hr_pred[idx])\n","\n","plt.figure(figsize=(20, 20))\n","\n","plt.subplot(1, 3, 1)\n","img = cv2.resize(np.squeeze(x_img[:,:,0]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","\n","plt.subplot(1, 3, 2)\n","output_0 = cv2.resize(np.squeeze(inv_hr_hmp_0[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\n","\"\"\"\n","plt.subplot(1, 4, 3)\n","output_0 = cv2.resize(np.squeeze(grad_hmp[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 3, 3)\n","output_0 = cv2.resize(np.squeeze(hr_hmp_0[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvi8FmQLmVz-"},"source":["print('Calculating HR hmp')\n","hr_hmp_1, hr_pred_1, hr_w1_1 = get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer2_ids, weight_layer=output_layer_ids[1] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JcpTDEGRmVz_"},"source":["inv_hr_hmp_1, inv_hr_pred_1, inv_hr_w1_1 =get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer2_ids,\n","                                                    weight_layer=output_layer_ids[1] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U_stiYqNmVz_"},"source":["for i in range(len(hr_hmp_1)):\n","    hr_hmp_1[i] = np.maximum(hr_hmp_1[i],0,hr_hmp_1[i])\n","    hr_hmp_1[i] = (hr_hmp_1[i]-hr_hmp_1[i].min())/(hr_hmp_1[i].max()-hr_hmp_1[i].min())\n","for i in range(len(inv_hr_hmp_1)):\n","    hr_hmp_1[i] = np.maximum(hr_hmp_1[i],0,hr_hmp_1[i])\n","    inv_hr_hmp_1[i] = (inv_hr_hmp_1[i]-inv_hr_hmp_1[i].min())/(inv_hr_hmp_1[i].max()-inv_hr_hmp_1[i].min())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ar2QjDGJmVz_"},"source":["#IDH HR_CAMS\n","\n","#idx = np.random.randint(0,len(_y))\n","x_img = np.copy(_x[idx])\n","y_img = np.copy(_y[idx])\n","print('Idx: ',idx,' Class: ',y_img)\n","#print('Predicted class - Base model: ',res_pred[idx],' HR_Cam: ',hr_pred[idx])\n","\n","plt.figure(figsize=(20, 20))\n","\n","plt.subplot(1, 3, 1)\n","img = cv2.resize(np.squeeze(x_img[:,:,0]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","\n","plt.subplot(1, 3, 2)\n","output_1 = cv2.resize(np.squeeze(inv_hr_hmp_1[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(-output_1, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 4, 3)\n","output_0 = cv2.resize(np.squeeze(grad_hmp[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 3, 3)\n","output_0 = cv2.resize(np.squeeze(hr_hmp_1[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"seqP3bmymV0A"},"source":["print('Calculating HR hmp')\n","hr_hmp_2, hr_pred_2, hr_w1_2 = get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer3_ids, \n","                                         weight_layer=output_layer_ids[2] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TzVtosk9mV0A"},"source":["inv_hr_hmp_2, inv_hr_pred_2, inv_hr_w1_2 =get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer3_ids,\n","                                                    weight_layer=output_layer_ids[2] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bk0v4U4_mV0A"},"source":["for i in range(len(hr_hmp_2)):\n","    hr_hmp_2[i] = np.maximum(hr_hmp_2[i],0,hr_hmp_2[i])\n","    hr_hmp_2[i] = (hr_hmp_2[i]-hr_hmp_2[i].min())/(hr_hmp_2[i].max()-hr_hmp_2[i].min())\n","for i in range(len(inv_hr_hmp_2)):\n","    hr_hmp_2[i] = np.maximum(hr_hmp_2[i],0,hr_hmp_2[i])\n","    inv_hr_hmp_2[i] = (inv_hr_hmp_2[i]-inv_hr_hmp_2[i].min())/(inv_hr_hmp_2[i].max()-inv_hr_hmp_2[i].min())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8-NPI2ctmV0A"},"source":["#MGMT HR_CAMS\n","\n","#idx = np.random.randint(0,len(_y))\n","x_img = np.copy(_x[idx])\n","y_img = np.copy(_y[idx])\n","print('Idx: ',idx,' Class: ',y_img)\n","#print('Predicted class - Base model: ',res_pred[idx],' HR_Cam: ',hr_pred[idx])\n","\n","plt.figure(figsize=(20, 20))\n","\n","plt.subplot(1, 3, 1)\n","img = cv2.resize(np.squeeze(x_img[:,:,0]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","\n","plt.subplot(1, 3, 2)\n","output_2 = cv2.resize(np.squeeze(inv_hr_hmp_2[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_2, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 4, 3)\n","output_0 = cv2.resize(np.squeeze(grad_hmp[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 3, 3)\n","output_0 = cv2.resize(np.squeeze(hr_hmp_2[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYpYBHrcmV0B"},"source":["print('Calculating HR hmp')\n","hr_hmp_3, hr_pred_3, hr_w1_3 = get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer4_ids, \n","                                         weight_layer=output_layer_ids[3] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"60ZEMLDGmV0B"},"source":["inv_hr_hmp_3, inv_hr_pred_3, inv_hr_w1_3 =get_heatmaps_hr(hr_model,_x, layer_ids = imp_layer4_ids,\n","                                                    weight_layer=output_layer_ids[3] )\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Qyv_K49mV0B"},"source":["for i in range(len(hr_hmp_3)):\n","    hr_hmp_3[i] = np.maximum(hr_hmp_3[i],0,hr_hmp_3[i])\n","    hr_hmp_3[i] = (hr_hmp_3[i]-hr_hmp_3[i].min())/(hr_hmp_3[i].max()-hr_hmp_3[i].min())\n","for i in range(len(inv_hr_hmp_3)):\n","    hr_hmp_3[i] = np.maximum(hr_hmp_3[i],0,hr_hmp_3[i])\n","    inv_hr_hmp_3[i] = (inv_hr_hmp_3[i]-inv_hr_hmp_3[i].min())/(inv_hr_hmp_3[i].max()-inv_hr_hmp_3[i].min())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5TFRrinrmV0C"},"source":["#1p19q HR_CAMS\n","\n","#idx = np.random.randint(0,len(_y))\n","x_img = np.copy(_x[idx])\n","y_img = np.copy(_y[idx])\n","print('Idx: ',idx,' Class: ',y_img)\n","#print('Predicted class - Base model: ',res_pred[idx],' HR_Cam: ',hr_pred[idx])\n","\n","plt.figure(figsize=(20, 20))\n","\n","plt.subplot(1, 3, 1)\n","img = cv2.resize(np.squeeze(x_img[:,:,0]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","\n","plt.subplot(1, 3, 2)\n","output_0 = cv2.resize(np.squeeze(inv_hr_hmp_3[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(-output_0, 'jet', interpolation='none', alpha=0.50)\n","\n","\"\"\"\n","plt.subplot(1, 4, 3)\n","output_0 = cv2.resize(np.squeeze(grad_hmp[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.50)\n","\"\"\"\n","plt.subplot(1, 3, 3)\n","output_3 = cv2.resize(np.squeeze(inv_hr_hmp_3[idx]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_3, 'jet', interpolation='none', alpha=0.50)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91q_vorUmV0C"},"source":["# plotting all images\n","\n","plt.figure(figsize=(20, 20))\n","\n","plt.subplot(1, 5, 1)\n","img = cv2.resize(np.squeeze(x_img[:,:,0]), tuple(input_shape[0:2]), 0, 0, 0, interpolation=cv2.INTER_LINEAR)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.gca().set_title('Original')\n","plt.subplot(1, 5, 2)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(output_0, 'jet', interpolation='none', alpha=0.70)\n","plt.gca().set_title('Grade')\n","plt.subplot(1, 5, 3)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(-output_1, 'jet', interpolation='none', alpha=0.70)\n","plt.gca().set_title('IDH')\n","plt.subplot(1, 5, 4)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(-output_2, 'jet', interpolation='none', alpha=0.70)\n","plt.gca().set_title('MGMT')\n","plt.subplot(1, 5, 5)\n","plt.imshow(img, 'gray', interpolation='none')\n","plt.imshow(-output_3, 'jet', interpolation='none', alpha=0.70)\n","plt.gca().set_title('1P/19Q')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdFoE2iOmV0J"},"source":[""],"execution_count":null,"outputs":[]}]}